# Lösungen der Übungsaufgaben {#loesungen}

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
```


## Kapitel 2: Objekte und Datenstrukturen {-}

__Lösung zur Übungsaufgabe \@ref(exr:ue2a1)__: 

Am sinnvollsten ist eine Liste `list()`, da diese heterogene Objekttypen beinhalten kann. Ein Dataframe lohnt sich bei nur einem Fall eher nicht.

```{r}
myself <- list(
  name = "Julian", # Texte als character
  year = 1988L, # Jahr als numeric - oder noch präziser als Integer
  from_bavaria = FALSE # Binäre Entscheidung als logical
)
```

Auch wenn wir hier alle Werte z. B. als Text repräsentieren könnten, ist es immer sinnvoll, den Objekttypen zu verwenden, der am besten zu den Werten passt -- numerische (`year`) und logische Objekte (`from_bavaria`) ermöglichen uns mehr Rechenoptionen, einfacheres Filtern von Datensätzen etc.

---

__Lösung zur Übungsaufgabe \@ref(exr:ue2a2)__:

```{r}
values <- c(1.2, 1.3, 0.8, 0.7, 0.7, 1.5, 1.1, 1.0, 1.1, 1.2, 1.1)
average <- mean(values)
above_average <- values > average
sum(above_average) / length(values)
```

1. In der ersten Zeile ordnen wir `values` einen numerischen Vektor aus einigen Zahlen zu
2. In der zweiten Zeile berechnen wir den Mittelwert von `values` und weisen diesen `average` zu.
3. `values > average` prüft nun für jeden Wert in `values`, ob dieser größer als der Mittelwert (gespeichert in `average` ist). Dies erzeugt einen `logical`-Vektor, den wir `above_average` zuweisen.
4. `sum(above_average)` zählt, wie viele `TRUE`-Werte in dem Vektor sind. Das ist darauf zurückzuführen, dass `TRUE` die numerische Entsprechung `1`, `FALSE` die numerische Entsprechung `0` hat; `sum()` wandelt den logischen Vektor automatisch in einen numerischen um. Wir teilen dies durch die Anzahl der Werte in `values` und bekommen als Ergebnis, dass 63.6 % der Werte in `values` über dem Mittelwert liegen. (Etwas schneller hätten wir dieses Ergebnis auch bekommen, wenn wir die letzte Zeile durch `mean(above_average)` ersetzen.)

---

__Lösung zur Übungsaufgabe \@ref(exr:ue2a3)__:

```{r}
str(mtcars)
```

`mtcars` enthält 11 Variablen, allesamt `numeric`, und 32 Fälle.

```{r}
mean(mtcars$cyl)
```

Im Durchschnitt haben die Fahrzeuge ca. 6.2 Zylinder.

Um einen Teildatensatz `cars_short`, der lediglich die Variablen `mpg` und `hp` enthält, zu erstellen, führen viele Wege zum Ziel, z. B.:

```{r}
cars_short <- mtcars[, c("mpg", "hp")]
cars_short <- mtcars[c("mpg", "hp")] # Steht nur eine Angabe in den eckigen Klammern, interpretiert R dies als Spaltenangabe
cars_short <- data.frame(mtcars$mpg, mtcars$hp)
```

## Kapitel 3: Funktionen {-}

__Lösung zur Übungsaufgabe \@ref(exr:ue3a1)__:

Um die gewünschte Sequenz zu erzeugen, benötigen wir die Argumente `from` (Startwert), `to` (Endwert) und `by` (Zunahmewert). 

```{r}
seq(from = 0, to = 100, by = 5)
```

Da es sich, wie wir der Funktionsdokumentation entnehmen können, dabei um die ersten drei Funktionsargumente handelt, können wir diese auch unbenannt übergeben:

```{r}
seq(0, 100, 5)
```

__Lösung zur Übungsaufgabe \@ref(exr:ue3a2)__:

Unsere Funktion benötigt lediglich ein Argument, die Temperatur in Grad Fahrenheit (als numerischen Wert), und soll diese in Grad Celsius mit der Formel $°C = (°F - 32) × 5/9$ umwandeln:

```{r}
fahrenheit_to_celsius <- function(fahrenheit) {
  celsius <- (fahrenheit - 32) * 5/9
  return(celsius)
}

# Unsere neue Funktion kann sogar mehrere Temperaturwerte auf einmal umrechnen
fahrenheit_to_celsius(c(0, 50, 80, 100))
```

__Lösung zur Übungsaufgabe \@ref(exr:ue3a3)__:

Für das erste zusätzliche Feature, der Anzahl der fehlenden Werte, müssen wir `descriptives_vector` lediglich ein Element hinzufügen (das wir z. B. `Missing` nennen), in dem eben diese Anzahl festgehalten wird. Mit der Funktion `is.na()` prüfen wir jeden Wert eines Vektors darauf, ob es sich um einen fehlenden Wert `NA` handelt, mit der Summenfunktion `sum()` können wir diese addieren. Wir ändern `descriptives_vector` daher wie folgt:

```{r, eval=FALSE}
  descriptives_vector <- c(
    n = length(x),
    Missing = sum(is.na(x)), # Hier zählen wir die fehlenden Werte
    M = mean(x, na.rm = na.rm),
    SD = sd(x, na.rm = na.rm),
    Minimum = min(x, na.rm = na.rm), 
    Maximum = max(x, na.rm = na.rm),
    Median = median(x, na.rm = na.rm)
  )
```

Für das zweite zusätzliche Feature, Rundung auf eine gewünsche Anzahl an Nachkommastelle, benötigen wir die `round()`-Funktion, mit dem wir `descriptives_vector` abschließend runden, und ein zusätzliches Argument, mit dem die gewünschte Anzahl an Nachkommastellen übergeben werden kann. Da dieses Argument bei der `round()`-Funktion `digits` heißt, nennen wir es aus Konsistenzgründen auch in unserer Funktion so. Um standardmäßig auf zwei Nachkommastellen zu runden, geben wir dem Argument den Default-Wert `2`. Der vollständige Funktionscode sieht also wie folgt aus:

```{r}
descriptives <- function(x, na.rm = FALSE, digits = 2) { # Zusätzliches Argument digits mit Default-Wert 2
  
  # Vektor mit Variablenbeschreibung erstellen
  descriptives_vector <- c(
    n = length(x),
    Missing = sum(is.na(x)), # Hier zählen wir die fehlenden Werte
    M = mean(x, na.rm = na.rm),
    SD = sd(x, na.rm = na.rm),
    Minimum = min(x, na.rm = na.rm), 
    Maximum = max(x, na.rm = na.rm),
    Median = median(x, na.rm = na.rm)
  )
  
  # Vektor runden
  descriptives_vector <- round(descriptives_vector, digits = digits)
  
  return(descriptives_vector)
}
```

Wir haben nun eine flexibel einsetzbare Funktion, um schnell relevante Kennwerte einer numerischen Variablen zu erhalten:

```{r}
descriptives(iris$Sepal.Length)
descriptives(mtcars$cyl, digits = 1)
```

## Kapitel 4: Kontrollstrukturen {-}

__Lösung zur Übungsaufgabe \@ref(exr:ue4a1)__:

Erneut gibt es verschiedene Möglichkeiten, den Entscheidungsbaum abzubilden. Wenn wir uns pro `if ()` bzw. `else ()` oder `else if ()` auf das Prüfen einer Bedingung beschränken wollen, benötigen wir einen verschachtelten Baum, also eine Bedinung in einer Bedingung:

```{r, eval=FALSE}
if (news_channel != "Internet") {             # Prüfen, ob news_channel NICHT "Internet" ist...
  news_category <- "Offline"                  # dann news_category "Offline" zuweisen
} else {                                      # Falls das nicht der Fall ist, also news_channel "Internet" ist..
  if (news_website == "Twitter") {            # dann prüfen wir ob news_category "Twitter" ist
    news_category <- "SNS"                    # falls das so ist, weisen wir news_category "SNS" zu
  } else if (news_website == "Facebook") {    # analog verfahren wir mit Facebook
    news_category <- "SNS"                    #
  } else if (news_website == "Instagram") {   # analog mit Instagram
    news_category <- "SNS"                    #
  } else {                                    # falls das alles nicht zutrifft
    news_category <- "Online: Sonstige"       # weisen wir "Online: Sonstige" zu
  }
}
```

Das erzeugt allerdings einen ziemlich langen Entscheidungsbaum und einige Redundanzen, da wir für `"Twitter"`, `"Facebook"` und `"Instagram"` jeweils dieselbe Aktion, `news_category <- "SNS"` ausführen. Wir können diese Bedingungen also auch verknüpfen:

```{r, eval=FALSE}
if (news_channel != "Internet") {             # Prüfen, ob news_channel NICHT "Internet" ist...
  news_category <- "Offline"                  # dann news_category "Offline" zuweisen
} else {                                      # Falls das nicht der Fall ist, also news_channel "Internet" ist..
  if (news_website == "Twitter" | news_website == "Facebook" | news_website == "Instagram") {
    news_category <- "SNS"                    # Alle Bedingungen mit ODER verbunden, dann SNS zuweisen
  } else {                                    # falls das nicht zutrifft
    news_category <- "Online: Sonstige"       # weisen wir "Online: Sonstige" zu
  }                                           # und haben uns einige Zeilen gespart
}
```

Tatsächlich können wir auch die Verschachtelung aufheben, da nach `if (news_channel != "Internet")` folgt, dass bei allen anschließenden `else if()`-Bedingungen `news_channel == "Internet"` ist: 

```{r, eval=FALSE}
if (news_channel != "Internet") {             
  news_category <- "Offline"                  
} else if (news_website == "Twitter" | news_website == "Facebook" | news_website == "Instagram") {
  news_category <- "SNS" 
} else {                                    
  news_category <- "Online: Sonstige" 
}
```

Und noch kürzer wir der Entscheidungsbaum, wenn wir den `%in%`-Operator verwenden:

```{r, eval=FALSE}
SNS <- c("Twitter", "Facebook", "Instagram")

if (news_channel != "Internet") {             
  news_category <- "Offline"                  
} else if (news_website %in% SNS) {
  news_category <- "SNS" 
} else {                                    
  news_category <- "Online: Sonstige" 
}
```

---

__Lösung zur Übungsaufgabe \@ref(exr:ue4a2)__:

Beim ersten Platzhalter müssen wir einen `for`-Loop, wie in Kapitel \@ref(forloops) beschrieben, einfügen und uns für einen Namen für das Iterator-Objekt entscheiden. Da wir über den Vektor `variables` loopen, bietet sich der Singular `variable` an (aber natürlich funktioniert auch jeder andere Objektname). Diesen müssen wir dann bei den folgenden Platzhaltern ergänzen:

```{r}
numeric_summary <- function(data) {
  
  # Alle Variablennamen in Vektor speichern
  variables <- names(data)
  
  # Leere Liste für Ausgabe vorbereiten
  summary_list <- list()
  
  # Über alle Variablen iterieren
  for (variable in variables) { # Wir loopen über variables
    variable_vector <- data[[variable]] # Und arbeiten nun immer mit dem Iterator-Objekt variable
    
    if (is.numeric(variable_vector)) { # Prüfen ob die Variable numerisch ist
      
      # Mittelwert und Standardabweichung dieser Variablen der summary_list hinzufügen
      summary_list[[variable]] <- c(
        M = mean(variable_vector),   
        SD = sd(variable_vector)
      )
    }
    
  }
  
  # Summary List ausgeben
  return(summary_list)
}
```

Diese Funktion erzeugt uns nun auf einen Schlag eine Kurzzusammenfassung anhand von Mittelwert und Standardabweichung _aller_ numerischen Variablen in einem Datensatz:

```{r}
numeric_summary(iris)
numeric_summary(mtcars)
```

## Kapitel 8: Daten laden, modifizieren und speichern {-}

__Lösung zur Übungsaufgabe \@ref(exr:ue8a1)__:

Wir benötigen die `read_csv()`-Funktion, da alle Werte durch Kommas getrennt sind. Falls der Datensatz im Hauptverzeichnis des Projektordners liegt, genügt die Angabe von `"facebook_europawahl.csv"` als Argument:

```{r, eval=FALSE}
facebook_europawahl <- read_csv("facebook_europawahl.csv")
```

Liegt der Datensatz in einem Unterordner, muss der Dateipfad entsprechend als Argument angepasst werden, z. b. `"data/facebook_europawahl.csv"`.

```{r, echo=FALSE}
facebook_europawahl <- read_csv("data/facebook_europawahl.csv")
```

---

__Lösung zur Übungsaufgabe \@ref(exr:ue8a2)__:

Um den Datensatz zu filtern, benötigen wir zunächst die Schreibweisen der Partei-Accounts. Hierzu bietet es sich an, die `party`-Variable auszuzählen:

```{r}
count(facebook_europawahl, party)
```

Ebenfalls optional, aber hilfreich ist es, die entsprechenden Parteiseiten in einem Vektor zu speichern:

```{r}
bt_parteien <- c("alternativefuerde", "B90DieGruenen", "CDU", "CSU", "FDP", "linkspartei", "SPD")
```

Nun filtern wir den Datensatz zunächst nach Parteien:

```{r}
df_bt_parteien <- filter(facebook_europawahl, party %in% bt_parteien)
```

Dann wählen wir nur die gewünschten Variablen aus:

```{r}
df_reduziert <- select(df_bt_parteien, party, timestamp, type,
                       comments_count, shares_count, reactions_count)
```

Und schließlich erzeugen wir die neue Variable `total_count`:

```{r}
df_mit_tc <- mutate(df_reduziert,
                    total_count = sum(c(comments_count, shares_count, reactions_count), na.rm = TRUE))

df_mit_tc
```

Warum addieren wir nicht einfach alle Spalten ohne die Summenfunktion?

```{r}
df_mit_total2 <- mutate(df_reduziert, total_count = comments_count + shares_count + reactions_count)

df_mit_total2
```

Dies führt augenscheinlich zunächst zum gleichen Ergebnis, hat aber ein Problem: kommen in einer der drei Facebook-Metriken fehlende Werte in Form von `NA` vor, ist das Ergebnis in `total_count` ebenfalls `NA`. Der Summenfunktion `sum()` können wir mit dem Argument `na.rm = TRUE` mitteilen, dass fehlende Werte nicht berücksichtigt werden sollen:

```{r, results="hold"}
# Fehlende Werte zählen:
sum(is.na(df_mit_tc$total_count))
sum(is.na(df_mit_total2$total_count))

```

Wählen wir diese `+`-Variante, haben wir also 5 fehlende Werte in unserem `total_count`, bei der ersten Variante keine.

Nun können wir den Datensatz abspeichern:

```{r, eval=FALSE}
write_csv(df_mit_tc, "data/df_reduziert.csv")
saveRDS(df_mit_tc, "data/df_reduziert.rds")
```

---

__Lösung zur Übungsaufgabe \@ref(exr:ue8a3)__:

Zunächst wählen wir nur die Woche vor der Wahl aus. Hierzu können wir die `timestamp`-Variable anfiltern -- Text, der wie ein Datum aussieht, wir dabei automatisch in ein Datum konvertiert:

```{r}
df_woche_vor_wahl <- filter(facebook_europawahl, timestamp >= "2019-05-20")
```

Nun gruppieren wir den Datensatz nach `party`:

```{r}
df_group_by_party <- group_by(df_woche_vor_wahl, party)
```

Und schließlich berechnen wir mit `summarize()` die gewünschten Kennwerte:

```{r}
summarize(df_group_by_party,
          M_comments = mean(comments_count, na.rm = TRUE),
          SD_comments = sd(comments_count, na.rm = TRUE),
          M_shares = mean(shares_count, na.rm = TRUE),
          SD_shares = sd(shares_count, na.rm = TRUE),
          M_reactions = mean(reactions_count, na.rm = TRUE),
          SD_reactions = sd(reactions_count, na.rm = TRUE))
```

## Kapitel 9: Der Pipe-Operator `%>%` {-}

__Lösung zur Übungsaufgabe \@ref(exr:ue9a1)__:

Dank Pipes können wir uns bei Übungsaufgabe \@ref(exr:ue8a2) die ganzen Zwischendatensätze sparen. Es ist jedoch sinnvoll, vor dem Speichern ein Datensatz-Objekt zuzuweisen, da wir dieses auf zweierlei Arten speichern möchten. Auch nach dem erstmaligen Laden bietet es sich an, den Originaldatensatz zunächst als Objekt zuzuweisen:

```{r, message=FALSE}
facebook_europawahl <- read_csv("data/facebook_europawahl.csv")

bt_parteien <- c("alternativefuerde", "B90DieGruenen", "CDU", "CSU", "FDP", "linkspartei", "SPD")

df_reduziert <- facebook_europawahl %>% 
  filter(party %in% bt_parteien) %>% 
  select(party, timestamp, type, comments_count, shares_count, reactions_count) %>% 
  mutate(total_count = sum(c(comments_count, shares_count, reactions_count), na.rm = TRUE))
  
df_reduziert
```

Anschließend können wir den Datensatz wieder speichern:

```{r, eval=FALSE}
write_csv(df_ungrouped, "data/df_reduziert.csv")
saveRDS(df_ungrouped, "data/df_reduziert.rds")
```

Die Schritte aus Übungsaufgabe \@ref(exr:ue8a3) können wir ebenfalls in eine Pipe verpacken -- da wir den Datensatz nicht speichern bzw. weiter mit diesem arbeiten, ist auch keine Objektzuweisung erforderlich:

```{r}
facebook_europawahl %>% 
  filter(timestamp >= "2019-05-20") %>% 
  group_by(party) %>% 
  summarize(M_comments = mean(comments_count, na.rm = TRUE),
            SD_comments = sd(comments_count, na.rm = TRUE),
            M_shares = mean(shares_count, na.rm = TRUE),
            SD_shares = sd(shares_count, na.rm = TRUE),
            M_reactions = mean(reactions_count, na.rm = TRUE),
            SD_reactions = sd(reactions_count, na.rm = TRUE))
```

## Kapitel 10: Daten umstrukturieren und zusammenfügen {-}

__Lösung zur Übungsaufgabe \@ref(exr:ue10a1)__:

Da wir den Datensatz vom Wide- ins Long-Format transformieren, benötigen wir die Funktion `pivot_longer()`:

```{r, message=FALSE}
facebook_europawahl <- read_csv("data/facebook_europawahl.csv")

facebook_europawahl %>% 
  select(id, party, timestamp, comments_count, shares_count, reactions_count) %>% 
  pivot_longer(c(comments_count, shares_count, reactions_count), names_to = "metric")
```

__Lösung zur Übungsaufgabe \@ref(exr:ue10a2)__:

Wir laden zunächst den zusätzlichen Datensatz:

```{r, message=FALSE}
facebook_codings <- read_csv("data/facebook_codings.csv")

facebook_codings
```

Wie wir sehen, ist die `id`-Variable anders sortiert als im Datensatz `facebook_europawahl`. Wollen wir die Datensätze mittels `bind_cols()` zusammenfügen, müssten wir `facebook_codings` vorab mittels `arrange()` entsprechend `facebook_europawahl` sortieren.

Sicherer und genauso simpel ist allerdings `left_join()`:

```{r}
joined_df <- facebook_europawahl %>% 
  left_join(facebook_codings, by = "id")

joined_df
```

Wir sehen, dass der neue Datensätze weiterhin 902 Zeilen hat, aber nun alle 38 Variablen aus beiden Datensätzen umfasst. Zur Sicherheit sollten wir überprüfen, ob doppelte Werte in der `id`-Variablen vorkommen, um auszuschließen, dass Fälle bei der Join-Operation verdoppelt wurden. Dafür können wir die `distinct()`-Funktion nutzen, die nur einzigartige Werte der angegebenen Variablen ausgibt:

```{r}
joined_df %>% 
  distinct(id)
```

902 einzigartige Werte in `id` -- es wurden also keine Fälle verdoppelt oder sind weggefallen.

## Kapitel 10: Daten visualisieren {-}

Für alle Aufgaben benötigen wir das Tidyverse und den Datensatz `facebook_europawahl.csv`. Zudem filtern wir in diesem nur die im Bundestag vertretenen Parteien an:

```{r, warning=FALSE, message=FALSE}
library(tidyverse)

bt_parteien <- c("alternativefuerde", "B90DieGruenen", "CDU", "CSU", "FDP", "linkspartei", "SPD")

facebook_europawahl <- read_csv("data/facebook_europawahl.csv") %>% 
  filter(party %in% bt_parteien)
```

__Lösung zur Übungsaufgabe \@ref(exr:ue11a1)__:

Als _Aesthetics_ weisen wir die Kommentarzahl (`comments_count`) der `x`-Achse, die Anzahl an Shares (`shares_count`) der `y`-Achse zu (oder andersum). Für Punktediagramme benötigen wie das _Geometric_ `geom_point()`:

```{r}
facebook_europawahl %>% 
  ggplot(aes(x = comments_count, y = shares_count)) +
  geom_point()
```

An der Warnmeldung sehen wir im Übrigen, dass 5 Posts nicht abgebildet werden -- hierbei handelt es sich um `NA`-Werte.

__Lösung zur Übungsaufgabe \@ref(exr:ue11a2)__:

Eine Möglichkeit, sowohl Partei (`party`) als auch Typ des Posts (`type`) eine Aesthetic zuzuweisen -- z. B. `color` (Punkt- bzw. Linienfarbe) für die Partei, `shape` (Punktform) für die den Typ des Beitrags:

```{r, warning=FALSE}
facebook_europawahl %>% 
  ggplot(aes(x = comments_count, y = shares_count, color = party, shape = type)) +
  geom_point()
```

Eine andere Möglichkeit besteht darin, zusätzlich mit Facets zu arbeiten:

```{r, warning=FALSE}
facebook_europawahl %>% 
  ggplot(aes(x = comments_count, y = shares_count, color = party)) +
  geom_point() +
  facet_wrap(~type)
```

__Lösung zur Übungsaufgabe \@ref(exr:ue11a3)__:

Einige Möglichkeiten zur Verbesserung und Verschönerung des Plots:

- Verwendung eines _Themes_
- Achsen-/Skalenbeschriftungen
- Verwendung der tatsächlichen Parteifarben
- Gleiche Skalierung von x- und y-Achse (da gleiche zugrundeliegende Einheit); der bisher noch unbekannte Befehl `coord_fixed()` sorgt dafür, dass Einheiten auf der x- und y-Achse gleich dargestellt werden:

```{r, warning=FALSE}
facebook_europawahl %>% 
  ggplot(aes(x = comments_count, y = shares_count, color = party, shape = type)) +
  geom_point() +
  scale_y_log10(name = "Anzahl der Shares", ) +
  scale_x_log10(name = "Anzahl der Kommentare",) +
  scale_color_manual(name = "Partei",
                     values = c("CDU" = "#000000",
                                "CSU" = "#6E6E6E",
                                "SPD" = "#FE2E2E",
                                "alternativefuerde" = "#81BEF7",
                                "FDP" = "#FFFF00",
                                "linkspartei" = "#DF01A5",
                                "B90DieGruenen" = "#01DF01"),
                     labels = c("alternativefuerde" = "AfD", 
                                "linkspartei" = "Linke", 
                                "B90DieGruenen" = "Grüne")) +
  scale_shape_discrete(name = "Art des Beitrags") +
  theme_bw() +
  coord_fixed()
```

